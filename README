nivdror1, ido.shachar
niv dror (305498198), Ido Shachar (311248355)
EX: 4

FILES:
Block.cpp
Block.h
CacheAlgorithm.cpp
CacheAlgorithm.h
FBRAlgo.h
FBRAlgo.cpp
LRUAlgo.cpp
LRUAlgo.h
LFUAlgo.cpp
LFUAlgo.h
CacheFS.cpp
CacheFile.h
CacheFile.cpp
README
Makefile

REMARKS:
These are some remarks that
I want the graders to know
about this submission.

ANSWERS:

part 1:
1) a) round robin:

the gantt chart:
0-2 - p1
2-4 - p2
4-6 - p3
6-8 - p4
8-9 - p5
9-11 - p1
11-12 - p2
12-14 - p4
14-16 - p1
16-18 - p4
18-20 - p1
20-21 - p4
21-23 - p1

turnaround time - 10.8 without cs

average wait time - 9.6 without cs

b) first come first serve:

the gantt chart:
0-10 - p1
10-13 - p2
13-15 - p3
15-22 - p4
22-23 - p1

turnaround time - 13.2 without cs

average wait time - 12 without cs

c) SRTF:

the gantt chart:

0-2 - p1
2-5 - p2
5-7 - p3
7-8 - p5
8-15 - p4
15-23 - p1

turnaround time - 8.2 without cs

average wait time - 3.6 without cs

d) priority scheduling

the gantt chart:

0-10 - p1
10-13 - p2
13-20 - p4
20-22 - p3
22-23 - p5

turnaround time - 14.2 without cs

average wait time - 13 without cs

e) priority scheduling with preemption:

the gantt chart:
0-2 - p1
2-5 - p2
5-12 - p4
12-14 - p3
14-22 - p1
22-23 - p5

turnaround time - 11.8 without cs

average wait time - 7.2 without cs

2)
Yes, it always provide a faster access time than fetching from the disk because the heap is
located at the main memory.
The main memory is DRAM and therefore accessing DRAM is much faster then accessing the disk which
 must be accessed mechanically.

3)

4)
An example when LRU is better than LFU:

Let the size of the cache be 4.
Initially the user reads the blocks 0,1,2 for a 1000 times.
Then the user reads the block 3,4 for infinity.

An example when LFU is better than LRU:
Let the size of the cache be 3.
The reading of the block is - 1,2,2,3,3,3,4,1,2

An example when LFU and LRU are both not good:
Let the size of the cache be 3.
The reading of the block is - 1,2,3,4,5,6,1,2,3

5)

The reason for that behaviour is to "factoring out locality", that means that if we have a
block/file that is very necessary for short period of time, and for any time else we don't mean
to access it again. So with that kind of file, certain block will have very high number of
reference - so it get stuck in the cache for a long time, although no one will access it again.

